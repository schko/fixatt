{"cells":[{"cell_type":"markdown","metadata":{},"source":["This notebook captures and saves frames that are associated with left or right turn in the DR(eye)VE dataset. Turns identified by the automated turn dectection pipeline provide an insight into where approximate a turn takes place.\n","\n","### Code execution and intended outcome\n","The automated turn dectection pipeline utilized speed, relative car position (course), longtitude and latitude information to identity the frames likely associated with a left or right turn. \n","\n","The final frames use for the model training are extracted based on the excel file locates at: $\\verb|../data/dreyeve/participant_driving_data.xlsx|$, which contains the manual annotated turns."]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import os\n","import configparser\n","import sys\n","\n","# Get the parent directory path\n","parent_directory = os.path.dirname(os.path.abspath('__file__'))\n","\n","# Construct the path to the config.ini file in the parent directory\n","config_file_path = os.path.join(parent_directory, '..', 'config.ini')\n","\n","# Load the configuration file\n","config = configparser.ConfigParser()\n","config.read(config_file_path)\n","\n","# Access configuration parameters\n","dreyeve_data_path = config['paths']['dreyeve_data_path']\n","\n","parent_dir = os.path.abspath(os.path.join(os.path.abspath(''), '..'))\n","sys.path.append(parent_dir)"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"q5U4HdP05WQp"},"outputs":[],"source":["import datetime\n","import glob\n","import os\n","import pickle\n","import shutil\n","from pathlib import Path\n","\n","import cv2\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","from preprocessing.heatmap_generator import *\n","from preprocessing.process_driving_video import *\n","from IPython.display import Video\n","\n","dreyeve_data_dir = f'..data/dreyeve_data_path/'\n","data_dir_list = sorted(glob.glob(os.path.join(dreyeve_data_dir,'*[!.txt]')))\n","result_output_path = 'real_motor_epochs/'\n","\n","get_turn_frame = False"]},{"cell_type":"markdown","metadata":{},"source":["# Automated turn dectection pipeline"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"AI_yoUlQ5WQu"},"outputs":[],"source":["def read_speedcourse_df(speedcourse_dir, et_dir):\n","\n","    \"\"\"\n","    This function takes two string arguments for the directory and returns a dataframe with information associated\n","    with the frames and a dataframe for eye tracking information for each frame.\n","\n","    Args:\n","        speedcourse_dir (str): directory to the speed, course, and coordinate .txt file\n","        et_dir (str): directory to the eye tracking .txt file \n","\n","    Return:\n","        speedcourse_df_sec (df): dataframe with all driving/car related data as well as turn identified with \n","        those informatoin. Only rows with longtitude and latitude information are available (~ every 1 second)\n","        et_df (df): dataframe for eye tracking data for each frame\n","    \"\"\"\n","\n","    # load .txt file \n","    speedcourse_df = pd.read_csv(speedcourse_dir, delimiter = '\\t', header = None)\n","    et_df = pd.read_csv(et_dir, delim_whitespace= True, header = 0)\n","    # add column for time and rename columns and index\n","    speedcourse_df = speedcourse_df.iloc[:, 0:5]\n","    speedcourse_df.columns = ['frame', 'speed', 'course','lat','lon']\n","    speedcourse_df['time_sec'] = speedcourse_df.frame / (25)\n","    speedcourse_df['time_min'] = speedcourse_df.time_sec.apply(lambda x: str(datetime.timedelta(seconds=x)))\n","    speedcourse_df = speedcourse_df.set_index(['frame'])\n","    # compute change in latitude and longitude information\n","    speedcourse_df_sec = (speedcourse_df.dropna()).copy() # drop rows without latitude or longtitude information\n","    speedcourse_df_sec['diff_lat'] = np.gradient(speedcourse_df_sec['lat'])\n","    speedcourse_df_sec['diff_lat_delta'] = speedcourse_df_sec.diff_lat.diff()\n","    speedcourse_df_sec['diff_lon'] = np.gradient(speedcourse_df_sec['lon'])\n","    speedcourse_df_sec['diff_lon_delta'] = speedcourse_df_sec.diff_lon.diff()\n","    # compute change in relative car position\n","    speedcourse_df_sec['course_delta'] = speedcourse_df_sec.course.diff()\n","    # rescale the course difference. keep the range of course_delta between -180 to 180. \n","    # e.g difference between 359 and 1 should be -2\n","    speedcourse_df_sec['course_delta_adj'] = speedcourse_df_sec.course_delta.apply(lambda x: x - 360 if x > 180 \n","                                                                                   else 360 - abs(x) if x < -180 \n","                                                                                   else x)\n","    # initial turn detection with speed and change in car position. Adjust sensitive of turn detection based on speed.\n","    # car returns to its initial position quicker during high speed condition. Adjusting turn detection sensitive by\n","    # changing the threshold (degree change in car position) to classify the turns.\n","\n","    # High speed condition - Make the detection more sensitive\n","    speedcourse_df_sec['turn_dir'] = speedcourse_df_sec.apply(lambda x: 'Left' if (x.course_delta_adj <= -4 and x.speed >= 50) \n","                                                                        else 'Right' if (x.course_delta_adj >= 4 and x.speed >= 50) \n","                                                                        else 'Straight', axis = 1) \n","    # low speed condition - Make the detection less sensitive\n","    speedcourse_df_sec['turn_dir'] = speedcourse_df_sec.apply(lambda x: 'Left' if (x.course_delta_adj < -5 and x.speed < 50) \n","                                                                        else 'Right' if (x.course_delta_adj > 5 and x.speed < 50) \n","                                                                        else x.turn_dir, axis = 1)\n","    # set speed threshold for identification of turns\n","    speedcourse_df_sec['turn_dir'] = speedcourse_df_sec.apply(lambda x: 'Straight' if x.speed < 20 else x.turn_dir, axis = 1)\n","\n","    return speedcourse_df_sec, et_df"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"uBpzRpPJ5WQv"},"outputs":[],"source":["def find_turn_frame(speedcourse_df_sec, convert2etg = True):\n","\n","    '''\n","    This function takes two arguments to generate finalized the detected turn.\n","\n","    Args:\n","        speedcourse_df_sec (df): dataframe contains preliminary detected turn and other frame related informatoin\n","        convert2etg (bool): boolean that determine if frame number will to be convert to match video with frequency\n","    Returns:\n","        turn_frame_list (list): list of frames where the turn takes place\n","        turn_dir_list (list): list of turn actions corresponding to the turn_frame_list\n","    '''\n","\n","    turn_frame_list = []\n","    turn_dir_list = []\n","    turn_dir_prev = None\n","\n","    for frame_no, row in speedcourse_df_sec.iterrows():\n","\n","        turn_dir_curr = row.turn_dir\n","\n","        # further verify if the detected turn should be consider as a turn with longtitude and latitude information\n","        if (abs(row.diff_lon_delta) < 1e-10 or abs(row.diff_lat_delta) < 1e-10) and (turn_dir_curr == \"Straight\"):\n","            turn_dir_curr = turn_dir_prev\n","            speedcourse_df_sec.at[frame_no, 'turn_dir_adj'] = turn_dir_prev\n","        # eliminate all frame that are straight and only keep the starting frame of the turn for consecutive frame with\n","        # with the same turn actions\n","        if turn_dir_curr != 'Straight' and turn_dir_curr != turn_dir_prev:\n","            frame_saved = frame_no - 15 # frame offset to capture driving scene before turn happens\n","            # eliminate frames close to each other\n","            if (not turn_frame_list) or (frame_saved - turn_frame_list[-1] >= 100):\n","                turn_frame_list.append(frame_saved)\n","                turn_dir_list.append(row.turn_dir)\n","\n","        turn_dir_prev = turn_dir_curr\n","    \n","    # convert frame number to match eye tracking video that has sampling rate of 30Hz (9000 frame)\n","    ## Frames for each turn were extracted using speed_course_coord.txt file (7500 frames). \n","    ## Eyetracking coordinate extracted from etg_samples.txt (9000 frames). \n","    ## In order to overlay eyetracking information on frames for each turn. \n","    ## These frame needs to be rescaled with frequency of 30Hz\n","    if convert2etg:\n","        turn_frame_list = [int(turn_frame*30/25) for turn_frame in turn_frame_list]\n","\n","    return turn_frame_list, turn_dir_list"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"q_RaLRXM5WQv"},"outputs":[],"source":["def capture_turn_frame(sbj_data_dir, runid, turn_frame_list):\n","\n","    '''\n","    This function takes the three arguments and captures frames that are associated with any turn actions.\n","\n","    Args:\n","        sbj_data_dir (str): directory of the run\n","        runid (int): number of the run\n","        turn_frame_list (list): list of frames where the turn takes place\n","\n","    '''\n","\n","    speedcourse_vid = os.path.join(sbj_data_dir,'video_etg.avi')\n","    video = cv2.VideoCapture(speedcourse_vid)\n","\n","    # Check if the video file was successfully opened\n","    if not video.isOpened():\n","        print(\"Error opening video file\")\n","\n","    save_frames_path = os.path.join(result_output_path,f'run_{runid}/saved_frames')\n","\n","    Path(save_frames_path).mkdir(parents=True, exist_ok=True)\n","\n","    for turn_frame_idx in turn_frame_list:\n","        # set video to the frame where the turn happens - avoid looping through entire video\n","        video.set(cv2.CAP_PROP_POS_FRAMES, turn_frame_idx)\n","        # capture and save the frame \n","        ret, frame = video.read()\n","        if ret:\n","            cv2.imwrite(os.path.join(save_frames_path,f\"frame_{turn_frame_idx}.jpg\"), frame)\n","        else: \n","            break"]},{"cell_type":"markdown","metadata":{},"source":["# Annotated frames extraction and processing"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# Regular frame's premotor period is defined as 1 second before turn actions are executing. \n","# For turns that are executed when the car approaches full stop before making the turn, the premotor period is \n","# longer than the 1 second. The decision of making the turn is likely made when participants decided to slow down the car \n","# to prepare for the turn\n","# The code below is to identify premotor frame that are made at low speed/approaching stop. \n","\n","# directory of file with annotated turns\n","all_driving_data_path = os.path.join(dreyeve_data_dir,\"run_driving_data.xlsx\")\n","\n","# with threshold = 20 or 15, 2 consecutive \"low speed\" turns (row 3602 and 3602 or row 4808 and 4810) with different \n","# direction will end up conflicting each other and have the same premotor period \n","speed_threshold = 10\n","# load file with annotated turns\n","driving_data_df = pd.read_excel(all_driving_data_path)\n","\n","start_idx = 0\n","premotor_frame_ls_df = None\n","\n","# turn frames at low speed\n","low_speed_frames = (pd.notna(driving_data_df['Direction'])) & (driving_data_df['speed'] < speed_threshold)\n","low_speed_frames_idx = list(driving_data_df[low_speed_frames].index)\n","\n","for idx in low_speed_frames_idx:\n","    # identify the frames before the participant reaches the target low speed threshold. The last frame will be the premotor \n","    # period frame\n","    premotor_frame = driving_data_df.iloc[start_idx:idx][driving_data_df.iloc[start_idx:idx].speed >= speed_threshold].iloc[-1]\n","    # the low speed frame associated with the premotor period frame\n","    premotor_frame['low_speed_frames'] = driving_data_df.iloc[idx].frame\n","    \n","    # the current run number \n","    low_speed_frame_runid = driving_data_df.iloc[idx]['run_id']\n","    premotor_frame_runid = premotor_frame['run_id']\n","    \n","    # to ensure the frames identified are for the same run\n","    if low_speed_frame_runid == premotor_frame_runid:\n","        start_idx = idx\n","        premotor_frame_ls_df = pd.concat([premotor_frame_ls_df, premotor_frame],axis=1)\n","    else:\n","        # Low speed turn frame detected in frame 21 for partcipant 26. Premotor period not available\n","        low_speed_frame_no = driving_data_df.iloc[idx]['frame']\n","        print(f'Low speed turn frame detected in frame {low_speed_frame_no} for partcipant {low_speed_frame_runid}. Premotor period not available')\n","        continue\n","        \n","premotor_frame_ls_df = premotor_frame_ls_df.T.iloc[:, [0,1,2,4,-1]] # extract only frame, id, speed, time, and low speed frame"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["# Find annotated frames from \n","\n","def find_steering_frame(driving_data_df, premotor_frame_ls_df, convert2etg = True):\n","\n","    '''\n","    This function takes 3 arguments to return the finalized list of frames for the turns\n","\n","    Args:\n","        driving_data_df (df): the dataframe with annotated turns for each frames\n","        premotor_frame_ls_df (df): the premotor period dataframe for turn  with low speed \n","        convert2etg (bool): boolean that determine if frame number will to be convert to match video with frequency\n","\n","    Returns: \n","        all_turn_frame_list (dict): dictionary with a list of identified turn frame for each runs\n","    '''\n","    \n","    all_turn_frame_list = {} \n","\n","    for run in range(1, 75):\n","\n","        # use only portion of the dataframe that is specifc to the run\n","        run_driving_data_df = driving_data_df[driving_data_df.run_id == run]\n","        turn_frame_list = list(run_driving_data_df[pd.notna(run_driving_data_df['Direction'])]['frame'])\n","        turn_dir_list = list(run_driving_data_df[pd.notna(run_driving_data_df['Direction'])]['Direction'])\n","        turn_dir_encoded_list = [0 if steer == \"Left\" else 1 for steer in turn_dir_list]\n","\n","        # handle low speed frame's premotor frame\n","        if run in list(premotor_frame_ls_df.run_id):\n","            # use only portion of the premotor frame dataframe that is specifc to the run\n","            run_premotor_frame_ls_df = premotor_frame_ls_df[premotor_frame_ls_df.run_id == run]\n","            # address runs that have mix low speed frame and \"normal\" speed frames.\n","            premotor_frame_list = [frame - 25 if frame not in list(run_premotor_frame_ls_df.low_speed_frames)\n","                                   else list(run_premotor_frame_ls_df[run_premotor_frame_ls_df.low_speed_frames == frame].frame)[0]\n","                                   for frame in turn_frame_list]\n","        else: \n","        # handle runs only with \"normal\" speed frame's premotor frame\n","            premotor_frame_list = list(np.array(turn_frame_list) - 25)\n","\n","        # eliminate turn does not have a premotor period (1 second), i.e. turns take place within the 1st second.\n","        premotor_frame_list = [premotor_frame if premotor_frame >= 0 else 0 for premotor_frame in premotor_frame_list]\n","\n","        # convert frame number to match eye tracking video that has sampling rate of 30Hz\n","        if convert2etg:\n","            turn_frame_list = [int(turn_frame*30/25) for turn_frame in turn_frame_list]\n","            premotor_frame_list = [int(premotor_frame*30/25) for premotor_frame in premotor_frame_list]\n","        \n","        # save turn frame related information to a dictionary by run number\n","        all_turn_frame_list[run] = (premotor_frame_list, \n","                                    turn_frame_list, \n","                                    turn_dir_list, \n","                                    turn_dir_encoded_list)\n","\n","    return all_turn_frame_list\n","    "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W9H1gFko5WQw"},"outputs":[],"source":["all_steering_dict = find_steering_frame(driving_data_df, premotor_frame_ls_df,convert2etg = True)\n","\n","# capture the turn frame\n","if get_turn_frame:\n","    for runid, data_dir in enumerate(data_dir_list[:-2]):\n","\n","        print(f\"Extracting run {runid + 1} motor frame ...\")\n","        # directory for the .txt file for eyetracking and car speed, position, and coordinate information\n","        speedcourse_dir = os.path.join(data_dir,'speed_course_coord.txt')\n","        et_dir = os.path.join(data_dir,'etg_samples.txt')\n","\n","        # load dataframe and extract list of frames associated with turns\n","        speedcourse_df, et_df = read_speedcourse_df(speedcourse_dir, et_dir)\n","        premotor_frames_list = all_steering_dict[runid+1][0]\n","        turn_frames_list = all_steering_dict[runid+1][1]\n","        turn_dir_list = all_steering_dict[runid+1][2]\n","        turn_dir_encoded_list = all_steering_dict[runid+1][3]\n","\n","        # Extract frames for each major and minor turns or lane changes\n","        capture_turn_frame(data_dir, runid+1, premotor_frames_list)\n","        # driving video directory\n","        speedcourse_vid = os.path.join(data_dir,'video_etg.avi')\n","        # save list of turn frames and associated information\n","        for idx in range(len(premotor_frames_list)):\n","            premotor_frame = premotor_frames_list[idx]\n","            frame_info = {\n","                \"run\": runid+1,\n","                \"trial\": idx+1, \n","                \"premotor_frame\": premotor_frame,\n","                \"turn_frame\": turn_frames_list[idx],\n","                \"steering_dir\": turn_dir_list[idx],\n","                \"steering_dir_encoded\": turn_dir_encoded_list[idx],\n","                }\n","            # generate fixation map, edges, and original image ... etc\n","            process_driving_video(premotor_frame, et_df, frame_info, output_path = result_output_path, vid_path=speedcourse_vid, \n","                            save_prepend=f'run_{runid+1}/frame{premotor_frame}', show_inline_images=False)\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
